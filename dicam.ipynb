{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import numpy as np\n","import os\n","import time\n","import torch\n","import torch.nn as nn\n","\n","\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T04:59:10.722460Z","iopub.status.busy":"2024-04-14T04:59:10.722066Z","iopub.status.idle":"2024-04-14T04:59:14.730291Z","shell.execute_reply":"2024-04-14T04:59:14.729093Z","shell.execute_reply.started":"2024-04-14T04:59:10.722428Z"},"trusted":true},"outputs":[],"source":["class Inc(nn.Module):\n","    def __init__(self,in_channels,filters):\n","        super(Inc, self).__init__()\n","        self.branch1 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n","            nn.LeakyReLU(),\n","            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(3, 3), stride=(1, 1),dilation=1,padding=(3-1) // 2),\n","            nn.LeakyReLU(),\n","            )   \n","        self.branch2 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1,padding=(1-1) // 2),\n","            nn.LeakyReLU(),\n","            nn.Conv2d(in_channels=filters, out_channels=filters, kernel_size=(5, 5), stride=(1, 1),dilation=1,padding=(5-1) // 2),\n","            nn.LeakyReLU(),\n","            )  \n","        self.branch3 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1),\n","            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n","            nn.LeakyReLU(),\n","\n","        )   \n","        self.branch4 = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=(1, 1), stride=(1, 1),dilation=1),\n","            nn.LeakyReLU(),\n","        )    \n","    def forward(self,input):\n","        o1 = self.branch1(input)\n","        o2 = self.branch2(input)\n","        o3 = self.branch3(input)\n","        o4 = self.branch4(input)\n","        return torch.cat([o1,o2,o3,o4],dim=1)\n","class Flatten(nn.Module):\n","    def forward(self, inp):\n","        return inp.view(inp.size(0), -1)\n","class CAM(nn.Module):\n","    def __init__(self,in_channels,reduction_ratio):\n","        super(CAM, self).__init__()\n","        self.module = nn.Sequential(\n","            nn.AdaptiveAvgPool2d((1,1)),\n","            Flatten(),\n","            nn.Linear(in_channels, in_channels // reduction_ratio),\n","            nn.Softsign(),\n","            nn.Linear(in_channels // reduction_ratio, in_channels ),\n","            nn.Softsign()\n","            )\n","    def forward(self,input):\n","        return input* self.module(input).unsqueeze(2).unsqueeze(3).expand_as(input)\n","\n","class DICAM(nn.Module):\n","    def __init__(self):\n","        super(DICAM, self).__init__()  # Corrected the superclass to DICAM\n","        self.layer_1_r = Inc(in_channels=1,filters= 64)\n","        self.layer_1_g = Inc(in_channels=1,filters= 64)\n","        self.layer_1_b = Inc(in_channels=1,filters= 64)\n","\n","        self.layer_2_r = CAM(256,4)\n","        self.layer_2_g = CAM(256,4)\n","        self.layer_2_b = CAM(256,4)\n","\n","        self.layer_3 = Inc(768,64)\n","        self.layer_4 = CAM(256,4)\n","\n","        self.layer_tail = nn.Sequential(\n","            nn.Conv2d(in_channels=256,out_channels=24,kernel_size=(3,3),stride=(1, 1),padding=(3-1) // 2),\n","            nn.LeakyReLU(),\n","            nn.Conv2d(in_channels=24,out_channels=3,kernel_size=(1,1),stride=(1, 1),padding=(1-1) // 2),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self,input):\n","        input_r = torch.unsqueeze(input[:,0,:,:], dim=1)\n","        input_g  = torch.unsqueeze(input[:,1,:,:], dim=1)\n","        input_b = torch.unsqueeze(input[:,2,:,:], dim=1)\n","        \n","        layer_1_r = self.layer_1_r(input_r)\n","        layer_1_g = self.layer_1_g(input_g)\n","        layer_1_b = self.layer_1_b(input_b)\n","\n","        layer_2_r = self.layer_2_r(layer_1_r)\n","        layer_2_g = self.layer_2_g(layer_1_g)\n","        layer_2_b = self.layer_2_b(layer_1_b)\n","\n","        layer_concat = torch.cat([layer_2_r,layer_2_g,layer_2_b],dim=1)\n","\n","        layer_3 = self.layer_3(layer_concat)\n","        layer_4 = self.layer_4(layer_3)\n","\n","        output = self.layer_tail(layer_4)\n","        return output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:03:29.426669Z","iopub.status.busy":"2024-04-14T05:03:29.426089Z","iopub.status.idle":"2024-04-14T05:03:29.488239Z","shell.execute_reply":"2024-04-14T05:03:29.486797Z","shell.execute_reply.started":"2024-04-14T05:03:29.426635Z"},"trusted":true},"outputs":[],"source":["dicam = DICAM()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:06:07.810253Z","iopub.status.busy":"2024-04-14T05:06:07.809458Z","iopub.status.idle":"2024-04-14T05:06:07.816646Z","shell.execute_reply":"2024-04-14T05:06:07.815455Z","shell.execute_reply.started":"2024-04-14T05:06:07.810217Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:06:13.591871Z","iopub.status.busy":"2024-04-14T05:06:13.591487Z","iopub.status.idle":"2024-04-14T05:06:13.786674Z","shell.execute_reply":"2024-04-14T05:06:13.785638Z","shell.execute_reply.started":"2024-04-14T05:06:13.591842Z"},"trusted":true},"outputs":[],"source":["chkpt = torch.load(r\"C:\\DEVELOPMENT\\Semester-projects\\DIP\\DICAM-Implementation\\ckpts\\UIEB\\DICAM_60.pt\", device)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:07:30.821644Z","iopub.status.busy":"2024-04-14T05:07:30.821238Z","iopub.status.idle":"2024-04-14T05:07:30.839639Z","shell.execute_reply":"2024-04-14T05:07:30.838850Z","shell.execute_reply.started":"2024-04-14T05:07:30.821615Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dicam.load_state_dict(chkpt[\"model_state_dict\"])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["INP_DIR=r\"C:\\DEVELOPMENT\\Semester-projects\\DIP\\DICAM-Implementation\\Data\\UIEB\\hazy_test\""]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu' "]},{"cell_type":"markdown","metadata":{},"source":["Number of channels = 3"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["ch = 3"]},{"cell_type":"markdown","metadata":{},"source":["## Custom preprocessor"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.file_list = os.listdir(root_dir)\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.root_dir, self.file_list[idx])\n","        image = Image.open(img_name).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image"]},{"cell_type":"markdown","metadata":{},"source":["We've re-sized the image 256x256 and converted into Tensor"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset and Dataloader"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["dataset = CustomDataset(root_dir=INP_DIR, transform=transform)\n","data_loader = DataLoader(dataset, batch_size=1, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Checkpoint DIR"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["CHKPT_DIR=r\"C:\\DEVELOPMENT\\Semester-projects\\DIP\\DICAM-Implementation\\ckpts\\UIEB\\DICAM_60.pt\""]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["result_dir = 'results/UIEB_DICAM/'\n","if not os.path.exists(result_dir):\n","    os.makedirs(result_dir)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 178/178 [22:16<00:00,  7.51s/it, name: 9_img_.png | new [hw]: 256/256]  "]},{"name":"stdout","output_type":"stream","text":["Total time taken in secs: 1336.227995634079\n","Per image (avg): 7.506898851876848\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["checkpoint = torch.load(CHKPT_DIR, device)\n","dicam.load_state_dict(checkpoint['model_state_dict'])\n","dicam.eval()\n","dicam.to(device)\n","\n","    \n","if __name__ =='__main__':\n","    st = time.time()\n","    with tqdm(total=len(dataset)) as t:\n","        for idx, img in enumerate(data_loader):\n","            img = img.to(device)\n","\n","            output = dicam(img)\n","            output = (output.clamp_(0.0, 1.0)[0].detach().cpu().numpy().transpose(1, 2, 0) * 255.0).astype('uint8')\n","\n","            output_image_path = os.path.join(result_dir, dataset.file_list[idx])\n","            Image.fromarray(output).save(output_image_path)\n","\n","            t.set_postfix_str(\"name: {} | new [hw]: {}/{}\".format(dataset.file_list[idx], output.shape[0], output.shape[1]))\n","            t.update(1)\n","\n","    end = time.time()\n","    print('Total time taken in secs: ' + str(end - st))\n","    print('Per image (avg): ' + str(float((end - st) / len(dataset))))\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":25869,"sourceId":30826,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
